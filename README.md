1)  Выбор метрики и обоснование ее выбора: 
 Для нашей задачи хорошо подойдет метрика recall, показывающая долю верно предсказанных болезней. Так как крайне важно правильно предсказать наличие болезни, именно эту метрику мы будем брать за основу при выборе лучшей модели на train части. Также, чтобы выявить количество ложно положительных результатов(то есть случаев, когда модель выявила болезнь у здорового человека), можно использовать метрику presicion. В качестве метрики, некоторым образом объединяющей две предыдущие, возьмем roc_auc. 

Лучшая модель выбирается по recall на train этапе.
Подсчет precision и roc_auc осуществляется на валидационной выборке, уже на обученной модели, результаты сохраняются в директории reports.

2)  Разделение данных train/val
Происходит в стейдже train_val_split, с помощью функции train_test_split из sklearn, выход - в data/processed.

3)  Генерация признаков
Происходит в стейдже feature_generating. Заполняются пустые колонки с помощью функции empty_column_filler, а также делается target encoding с помощью класса TargetEncoder, выход - в data/processed.
 
4)  Обучение модели
  1.Происходит в стейдже train_models. В ходе треникровки с помощью gridSearchCV выбирается лучшие параметры для catboost модели и для RandomForestClassifier. Модели     сохраняются в папку models.
  2.Также в стейдже creating_pipelines создаются два sklearn pipeline для обеих моделей. В пайплайне для catboost - заполнение пустых полей, в пайплайне для RandomForestClassifier - заполнение пустых полей и target encoding. Fit для обоих пайплайнов происходит в create_pipelines.py.
  
5)  Оценка модели по метрике качества, выбранном в первом пункте на val датасете и сохранение метрик / графиков.
  Происходит в стейдже eval_models_print_graphs. Сохраняет метрики в reports/evaluation.json, графики - в reports/figures
